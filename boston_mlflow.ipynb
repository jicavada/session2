{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shutil  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete last runs directory\n",
    "try:\n",
    "    shutil.rmtree('./mlruns')\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Can't find folder mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = load_boston(return_X_y=True)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,target,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(y,ypred):\n",
    "    mae = mean_absolute_error(y,ypred)\n",
    "    mse = mean_squared_error(y, ypred)\n",
    "    R2 = r2_score(y,ypred)\n",
    "    y,ypred = np.array(y), np.array(ypred)\n",
    "    mape = np.mean(np.abs((y - ypred) / y)) * 100\n",
    "#     print(\"MAE:{0:.3f}, MSE:{1:.2f}, R2:{2:.2f}\".format(mae, mse, R2))\n",
    "    return mae,mse,R2,mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elastic_net(a,l,exp = None):\n",
    "    with mlflow.start_run(experiment_id=exp): #start mlflow run\n",
    "        en = ElasticNet(alpha=a,l1_ratio=l)\n",
    "        en.fit(X_train,y_train)\n",
    "        y_pred = en.predict(X_test)\n",
    "        \n",
    "        #calculate errors\n",
    "        mae,mse,R2,mape = calculate_errors(y_test,y_pred)\n",
    "        errors = mae,mse,R2,mape\n",
    "        print(\"MAE:{0:.3f}, MSE:{1:.2f}, R2:{2:.2f}\".format(mae, mse, R2))\n",
    "        \n",
    "        #log metris and parmeters\n",
    "        mlflow.log_metrics({\"MAE\":mae,\"MSE\":mse, \"R2\":R2, \"MAPE\":mape})\n",
    "        mlflow.log_params({\"alpha\":a,\"l1_ratio\":l})\n",
    "        \n",
    "        #register model\n",
    "        mlflow.sklearn.log_model(en, \"model\")\n",
    "        \n",
    "        #save error plot\n",
    "        plt.figure()\n",
    "        plt.bar(['mae','mse','R2','mape'],errors,color=['blue','red','green','orange']);\n",
    "        plt.title(\"Errors\")\n",
    "        plt.savefig(\"errors.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"errors.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with different alpha and l1 ratio values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:3.787, MSE:32.25, R2:0.61\n",
      "MAE:3.776, MSE:32.21, R2:0.61\n",
      "MAE:3.764, MSE:32.16, R2:0.61\n",
      "MAE:3.749, MSE:32.11, R2:0.61\n",
      "MAE:3.882, MSE:33.66, R2:0.59\n",
      "MAE:3.866, MSE:33.58, R2:0.59\n",
      "MAE:3.845, MSE:33.41, R2:0.59\n",
      "MAE:3.810, MSE:33.10, R2:0.59\n",
      "MAE:3.936, MSE:34.57, R2:0.58\n",
      "MAE:3.929, MSE:34.60, R2:0.58\n",
      "MAE:3.914, MSE:34.49, R2:0.58\n",
      "MAE:3.887, MSE:34.24, R2:0.58\n",
      "MAE:3.966, MSE:35.23, R2:0.57\n",
      "MAE:3.968, MSE:35.38, R2:0.57\n",
      "MAE:3.970, MSE:35.47, R2:0.57\n",
      "MAE:3.968, MSE:35.53, R2:0.57\n"
     ]
    }
   ],
   "source": [
    " for a in np.arange(0.1, 1, 0.25):\n",
    "        for l in np.arange(0.1, 1, 0.25):\n",
    "            train_elastic_net(a,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target mean:22.532806324110677\n",
      "target std:9.188011545278203\n"
     ]
    }
   ],
   "source": [
    "print(\"target mean:{}\".format(target.mean()))\n",
    "print(\"target std:{}\".format(target.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = mlflow.create_experiment(name=\"normalized data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.normalize(data)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,target,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:5.762, MSE:72.00, R2:0.12\n",
      "MAE:5.731, MSE:71.32, R2:0.13\n",
      "MAE:5.698, MSE:70.70, R2:0.13\n",
      "MAE:5.723, MSE:70.57, R2:0.14\n",
      "MAE:6.041, MSE:76.93, R2:0.06\n",
      "MAE:6.015, MSE:76.32, R2:0.07\n",
      "MAE:5.959, MSE:75.21, R2:0.08\n",
      "MAE:5.821, MSE:72.91, R2:0.11\n",
      "MAE:6.121, MSE:78.68, R2:0.04\n",
      "MAE:6.111, MSE:78.46, R2:0.04\n",
      "MAE:6.089, MSE:77.95, R2:0.05\n",
      "MAE:6.026, MSE:76.54, R2:0.06\n",
      "MAE:6.163, MSE:79.55, R2:0.03\n",
      "MAE:6.165, MSE:79.58, R2:0.03\n",
      "MAE:6.166, MSE:79.59, R2:0.03\n",
      "MAE:6.166, MSE:79.59, R2:0.03\n"
     ]
    }
   ],
   "source": [
    " for a in np.arange(0.1, 1, 0.25):\n",
    "        for l in np.arange(0.1, 1, 0.25):\n",
    "            train_elastic_net(a,l,exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can serve the model as a REST API \n",
    "`mlflow models serve -m [model_path] -p [port]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And then call the API to make a prediction for us \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[0,1,2,3,4,5,6,7,8,9,10,11,12],\"index\":[329],\"data\":[[0.0001176914,0.0,0.0056710311,0.0,0.0008051464,0.0110847655,0.0301054738,0.0091272095,0.007001273,0.7526368457,0.0295803784,0.656736909,0.0128473359]]}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first we need to turn one of the test rows into json format\n",
    "X_test.loc[[329]].to_json(orient='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we are ready to call the API service and get a reply  \n",
    "`curl http://127.0.0.1:2323/invocations -H 'Content-Type: application/json' -d '{\"columns\":[0,1,2,3,4,5,6,7,8,9,10,11,12],\"data\":[[0.06724,0.0,3.24,0.0,0.46,6.333,17.2,5.2146,4.0,430.0,16.9,375.21,7.34]]}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also use mlflow to make a prediction out of a csv or json file\n",
    "First, we need to have the data we want to predict in csv format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv (r'data.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mlflow models predict -m mlruns/1/281e22a41418413c8e0ca608aeb78289/artifacts/model/ -i data.csv  -t csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
